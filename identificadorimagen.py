# -*- coding: utf-8 -*-
"""IdentificadorImagen.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eLOFwARvA19YRC3kQ-XeVfqQzMIW6rxf
"""

# Importacion de las librerias
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras import layers
from keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

# Cargar los datos

from keras.datasets import cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Mirar los tipos de datos que tenemos
print(type(x_train))
print(type(y_train))
print(type(x_test))
print(type(y_test))

# son array

# obtencion la forma de las matrices

print('x_train shape:', x_train.shape)
print('x_train shape:', y_train.shape)
print('x_train shape:', x_test.shape)
print('x_train shape:', y_test.shape)

# Eche un vistazo a la primera imagen como una matriz
index = 25
x_train[index]

img = plt.imshow(x_train[index])

# Obtener la etiqueta de la imagen
print('The image label is:', y_train[index])

# Obtener la clasificacion de la imagen
classification = ['avión', 'automóvil', 'pájaro', 'gato', 'venado', 'perro', 'rana', 'caballo', 'barco', 'turco']
#Imprime la clase de la imagen
print ('La imagene es:', classification[y_train[index][0]])

#Convierte las etiquetas en un conjunto de 10 numeros para ingresas a la red nueronal
y_train_one_hot = to_categorical(y_train)
y_test_one_hot = to_categorical(y_test)

#Imprime las nuevas etiquetas
print(y_train_one_hot)

#Imprime la nueva etiqueta de la imagen / imagen de arriba
print('The one nhot label is:', y_train_one_hot[index])

#Normalizar los pixeles para que tengan valores entre 0 y 1
x_train = x_train / 255
x_test = x_test / 255

x_train[index]

#Crea la arquitectura de modelos
model = Sequential()

#Agrega la primera capa
model.add(Conv2D(32,(5,5), activation='relu', input_shape=(32,32,3)))

#Agregar una capa de agrupación
model.add(MaxPooling2D(pool_size=(2,2)))

#Agregar otra capa de convolucion
model.add(Conv2D(32,(5,5), activation='relu'))

#Agregar una capa de agrupación
model.add(MaxPooling2D(pool_size=(2,2)))

#Agregar una capa aplanadora
model.add(Flatten())

#Agregar una capa con 1000 neuronas
model.add(Dense(1000, activation='relu'))

#Agregar una capa de caida
model.add(Dropout(0.5))

#Agregar una capa con 500 neuronas
model.add(Dense(500, activation='relu'))

#Agregar una capa de caida
model.add(Dropout(0.5))

#Agregar una capa con 250 neuronas
model.add(Dense(250, activation='relu'))

#Agregar una capa con 10 neuronas
model.add(Dense(10, activation='softmax'))

#Compila el modelo
model.compile(loss = 'categorical_crossentropy',
              optimizer = 'adam',
              metrics = ['accuracy'])

#Entrena el modelo
hist = model.fit( x_train, y_train_one_hot,
                 batch_size = 256,
                 epochs = 10,
                 validation_split = 0.2)

#Evaluar el modelo utilizando el conjunto de datos de prueba
model.evaluate(x_test, y_test_one_hot)[1]

#Visualice la precision de los modelos
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc = 'upper right')
plt.show()

#Visualice el modelo de perdida
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train','Val'], loc='upper right')
plt.show()

#Prueba el modelo con un ejemplo
from google.colab import files
uploaded = files.upload()

#Mostrar la imagen
new_image = plt.imread('carito.jpg')
img = plt.imshow(new_image)

#Cambiar el tamaño de la imagen
from skimage.transform import resize
resized_image = resize(new_image, (32,32,3))
img = plt.imshow(resized_image)

#Obtenga las predicciones de los modelos
predictions = model.predict(np.array([resized_image]))

#Muestra de la Prediccion
predictions

#Ordene las predicciones de menor a mayor
list_index = [0,1,2,3,4,5,6,7,8,9]
x = predictions

for i in range(10):
  for j in range(10):
    if x[0][list_index[i]] > x[0][list_index[j]]:
      temp = list_index[i]
      list_index[i] = list_index[j]
      list_index[j] = temp

  #Mostrar las etiquetas ordenadas en orden
  print(list_index)

#Imprime las primeras 5 predicciones
for i in range(5):
  print(classification[list_index[i]], ':', round(predictions[0][list_index[i]]*100,2), '%')